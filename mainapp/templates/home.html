<!doctype html>
<html>

<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="shortcut icon" href="{{ url_for('static', filename='favicon.ico') }}">
    <title>Mandarin Tone Analyzer</title>
</head>

<body class="min-h-screen bg-slate-50 grid place-items-center p-6">
    <div class="w-full max-w-md bg-white border border-slate-200 rounded-2xl p-6 shadow-sm space-y-4">
        <div>
            <h1 class="text-lg font-semibold">Audio upload test</h1>
            <p id="s" class="text-sm text-slate-600">Click Record</p>
        </div>
        <div id="hanzi" class="text-3xl font-semibold"></div>
        <div id="pinyin" class="text-slate-600"></div>
        <div class="flex gap-2">
            <button id="rec" class="flex-1 rounded-xl bg-red-600 text-white py-2 text-sm font-medium">Record</button>
            <button id="stop" disabled
                class="flex-1 rounded-xl bg-slate-200 text-slate-900 py-2 text-sm font-medium disabled:opacity-50">Stop</button>
        </div>
        <div class="flex gap-2">
            <button id="new" onclick="loadPhrase()" class="flex-1 rounded-xl bg-green-600 text-white px-4 py-2 text-sm font-medium">New</button>
            <button id="listen" class="flex-1 rounded-xl bg-slate-900 text-white px-4 py-2 text-sm font-medium">Listen</button>
        </div>
        <div class="flex gap-2">
            <button id="compare" type="button" class="rounded-xl bg-amber-600 text-white px-3 py-2 text-sm font-medium">Compare</button>
        </div>
        <div id="result" class="rounded-xl bg-slate-100 p-3 text-sm"></div>
        <img id="plot" class="w-full rounded-xl border border-slate-200 hidden" />
        <audio id="p" controls class="w-full"></audio>
    </div>

    <script>
        // grab elements
        const s = document.getElementById("s"); // status text
        const recBtn = document.getElementById("rec"); // "Record" button
        const stopBtn = document.getElementById("stop"); // "Stop" button
        const p = document.getElementById("p"); // <audio>
        const listenBtn = document.getElementById("listen") // grab the Listen button

        // MediaRecorder state
        let mr; // MediaRecorder instance (created when recording starts)
        let chunks = []; // array of Blob parts (recorded audio pieces)
        let currentPhraseId = "" // stores phrase_id so uploads can attach it
        let lastFileUrl = "" // store the most recent upload so Compare knows what to analyze

        async function loadPhrase() {
            const r = await fetch("/api/phrase"); // call Flask route
            const phrase = await r.json(); // {phrase_id, hanzi, pinyin}
            currentPhraseId = phrase.phrase_id; // cache phrase_id for later upload
            document.getElementById("hanzi").textContent = phrase.hanzi; // show 汉字
            document.getElementById("pinyin").textContent = phrase.pinyin; // show pinyin
        }

        // when user clicks "Record":
        recBtn.onclick = async () => {

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true }); // ask browser for microphone access and audio stream

            mr = new MediaRecorder(stream); // create MediaRecorder to encode audio in browser-supported format

            chunks = []; // reset `chunks` for new recording

            mr.ondataavailable = (e) => chunks.push(e.data); // MediaRecorder fires this periodically

            mr.onstop = async () => { // runs when recording stops
            s.textContent = "Uploading...";

            const blob = new Blob(chunks, { type: mr.mimeType }); // put the chunks into one audio file (mr.mimeType tso that it matches the browser)

            const fd = new FormData(); // build a multipart payload for flask
            fd.append("audio", blob, "recording.webm");
            fd.append("phrase_id", currentPhraseId) // attach the current phrase_id to this recording

            const r = await fetch("/api/upload", { method: "POST", body: fd }); // upload to flask

            const j = await r.json(); // parse json response

            p.src = j.file_url + "?t=" + Date.now(); // point the audio player at the server-served file

            lastFileUrl = j.file_url // cache last upload URL for the compare step

            p.play().catch(() => {}); // try autoplay (does nothing if browser blocks it)

            s.textContent = "Done!";
            };

            mr.start(); // start recording now

            s.textContent = "Recording..."; // update UI
            recBtn.disabled = true; // update UI
            stopBtn.disabled = false; // update UI
        };

        // when user clicks "Stop":
        stopBtn.onclick = () => {

            mr.stop(); // tell MediaRecorder to finalize recording

            mr.stream.getTracks().forEach((t) => t.stop()); // stop the mic stream tracks

            recBtn.disabled = false; // update UI
            stopBtn.disabled = true; // update UI
        };

        loadPhrase(); // initialize UI with a random phrase

        const compareBtn = document.getElementById("compare"); // compare button
        const resultEl = document.getElementById("result"); // result <pre>
        const plotEl = document.getElementById("plot"); // plot <img>

        compareBtn.onclick = async () => {
            if (!lastFileUrl) { // block compare until recorded once
                s.textContent = "Record something first."; 
                return;
            }

            s.textContent = "Comparing...";

            const r = await fetch("/api/compare", { // call backend
                method: "POST",
                headers: { "Content-Type": "application/json" },
                body: JSON.stringify({ phrase_id: currentPhraseId, file_url: lastFileUrl }) // payload
            });

            const j = await r.json(); // parse response JSON
            
            // show overall score + per-syllable scores (simple UI)
            const overall = j.score ?? "?"
            const sylls = Array.isArray(j.syllables) ? j.syllables : []

            resultEl.innerHTML = `
                <div class="flex items-center justify-between">
                    <div class="font-semibold">Overall</div>
                    <div class="font-mono text-base">${overall}</div>
                </div>

                <div class="mt-3 grid grid-cols-2 gap-2">
                    ${sylls.map(s => {
                    const sc = s.score ?? 0
                    const cls =
                        sc >= 85 ? "bg-emerald-600" :
                        sc >= 70 ? "bg-amber-500" :
                                "bg-red-600"
                    const label = s.syllable ?? `#${(s.idx ?? 0) + 1}`
                    return `
                        <div class="flex items-center justify-between rounded-lg bg-white px-3 py-2 border border-slate-200">
                        <div class="text-slate-700">${label}</div>
                        <div class="font-mono text-white px-2 py-0.5 rounded-md ${cls}">${sc}</div>
                        </div>
                    `
                    }).join("")}
                </div>
            `

            if (j.plot_url) { // show plot if backend returns one
                plotEl.src = j.plot_url + "?t=" + Date.now(); // cache-bust
                plotEl.classList.remove("hidden"); // unhide
            }

            s.textContent = "Done!"; // update status
        };

        function speakMandarin(text) {
            const u = new SpeechSynthesisUtterance(text); // create speech request
            u.lang = "zh-CN"; // request Mandarin voice
            u.rate = 0.95; // slightly slower for learners
            speechSynthesis.cancel(); // stop any current speech so it doesn’t overlap
            speechSynthesis.speak(u); // speak now
        };

        listenBtn.onclick = () => {
            const hanzi = document.getElementById("hanzi").textContent; // read current 汉字 from UI
            if (hanzi) speakMandarin(hanzi); // speak the phrase
        };
    </script>
</body>

</html>